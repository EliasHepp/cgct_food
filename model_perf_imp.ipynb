{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from main import *\n",
    "from model_perf import *\n",
    "from openpyxl import Workbook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-world - train\n",
    "df = pd.read_csv('data/food_df_ana.csv') \n",
    "year = 2018\n",
    "df = df[df['year'] == year]\n",
    "\n",
    "# Prepare real world data\n",
    "X = df.iloc[:, 5:].to_numpy()\n",
    "A = df.iloc[:, 4].to_numpy()\n",
    "Y = df.iloc[:, 2].to_numpy()\n",
    "\n",
    "n = X.shape[0]\n",
    "p = X.shape[1]\n",
    "\n",
    "data = np.concatenate([Y.reshape(n,1), A.reshape(n,1), X],axis=1)\n",
    "\n",
    "# Data standardization: min-max scaler\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data[:,2:])\n",
    "data_train = np.concatenate([data[:,0:2], data_scaled], axis=1)\n",
    "\n",
    "# Real world - test\n",
    "df = pd.read_csv('data/food_df_ana.csv')\n",
    "year = 2019\n",
    "df = df[df['year'] == year]\n",
    "\n",
    "# Prepare real world data\n",
    "X = df.iloc[:, 5:].to_numpy()\n",
    "A = df.iloc[:, 4].to_numpy()\n",
    "Y = df.iloc[:, 2].to_numpy()\n",
    "\n",
    "n = X.shape[0]\n",
    "p = X.shape[1]\n",
    "\n",
    "data2 = np.concatenate([Y.reshape(n,1), A.reshape(n,1), X],axis=1)\n",
    "\n",
    "# Data standardization: min-max scalerC\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled2 = scaler.fit_transform(data2[:,2:])\n",
    "data_test = np.concatenate([data2[:,0:2], data_scaled2], axis=1)\n",
    "\n",
    "# Hyperpar list\n",
    "hyper_opt_list = open(\"hyperpars/hyperpars_opt_real.txt\", \"r\")\n",
    "hyper_opt_list = hyper_opt_list.read()\n",
    "hyper_opt = ast.literal_eval(hyper_opt_list)\n",
    "\n",
    "for i in range(len(hyper_opt)):\n",
    "    for key in hyper_opt[i].keys():\n",
    "        hyper_opt[i][key] = [hyper_opt[i][key]]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['lm', 'nn', 'gps', 'dr', 'sci', 'cgct_gps', 'rf', 'cgct_rf', 'cf', 'cgct_cf']\n",
    "#models = [\"cf\"]\n",
    "# Set all seeds\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Get results\n",
    "res_table = np.empty(shape=(10,10))\n",
    "for l in range(10):\n",
    "    test_loss = []\n",
    "    for i, model in enumerate(models):\n",
    "        cv_results = get_model_error(data_train, data_test, model, hyper_opt[i])\n",
    "        test_loss.append(cv_results[0]['loss'])\n",
    "    res_table[:,l] = np.array(test_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get results into format for export\n",
    "\n",
    "res_df = pd.DataFrame(np.transpose(res_table), columns=models)\n",
    "res_df.insert(0, \"measure\", [f\"run {i+1}\" for i in range(len(res_table.T))])\n",
    "\n",
    "stats = {\n",
    "    \"measure\": [\"mean\", \"median\", \"sd\"],\n",
    "    **{model: [res_df[model].mean(), res_df[model].median(), res_df[model].std()] for model in res_df.columns if model != \"measure\"}\n",
    "}\n",
    "\n",
    "stats_df = pd.DataFrame(stats)\n",
    "result_df = pd.concat([res_df, stats_df], ignore_index=True)\n",
    "\n",
    "result_df.to_csv(\"outputs/model_perf_real.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real World Large Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-world - train\n",
    "df = pd.read_csv('data/food_df_ana_large.csv') \n",
    "year = 2018\n",
    "df = df[df['year'] == year]\n",
    "\n",
    "# Prepare real world data\n",
    "X = df.iloc[:, 5:].to_numpy()\n",
    "A = df.iloc[:, 4].to_numpy()\n",
    "Y = df.iloc[:, 2].to_numpy()\n",
    "\n",
    "n = X.shape[0]\n",
    "p = X.shape[1]\n",
    "\n",
    "data = np.concatenate([Y.reshape(n,1), A.reshape(n,1), X],axis=1)\n",
    "\n",
    "# Data standardization: min-max scaler\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data[:,2:])\n",
    "data_train = np.concatenate([data[:,0:2], data_scaled], axis=1)\n",
    "\n",
    "# Real world - test\n",
    "df = pd.read_csv('data/food_df_ana_large.csv')\n",
    "year = 2019\n",
    "df = df[df['year'] == year]\n",
    "\n",
    "# Prepare real world data\n",
    "X = df.iloc[:, 5:].to_numpy()\n",
    "A = df.iloc[:, 4].to_numpy()\n",
    "Y = df.iloc[:, 2].to_numpy()\n",
    "\n",
    "n = X.shape[0]\n",
    "p = X.shape[1]\n",
    "\n",
    "data2 = np.concatenate([Y.reshape(n,1), A.reshape(n,1), X],axis=1)\n",
    "\n",
    "# Data standardization: min-max scalerC\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled2 = scaler.fit_transform(data2[:,2:])\n",
    "data_test = np.concatenate([data2[:,0:2], data_scaled2], axis=1)\n",
    "\n",
    "# Hyperpar list\n",
    "hyper_opt_list = open(\"hyperpars/hyperpars_opt_real_large.txt\", \"r\")\n",
    "hyper_opt_list = hyper_opt_list.read()\n",
    "hyper_opt = ast.literal_eval(hyper_opt_list)\n",
    "\n",
    "for i in range(len(hyper_opt)):\n",
    "    for key in hyper_opt[i].keys():\n",
    "        hyper_opt[i][key] = [hyper_opt[i][key]]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['lm', 'nn', 'gps', 'dr', 'sci', 'cgct_gps', 'rf', 'cgct_rf', 'cf', 'cgct_cf']\n",
    "# Set all seeds\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Get results\n",
    "res_table = np.empty(shape=(10,10))\n",
    "for l in range(10):\n",
    "    test_loss = []\n",
    "    for i, model in enumerate(models):\n",
    "        cv_results = get_model_error(data_train, data_test, model, hyper_opt[i])\n",
    "        test_loss.append(cv_results[0]['loss'])\n",
    "    res_table[:,l] = np.array(test_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get results into format for export\n",
    "\n",
    "res_df = pd.DataFrame(np.transpose(res_table), columns=models)\n",
    "res_df.insert(0, \"measure\", [f\"run {i+1}\" for i in range(len(res_table.T))])\n",
    "\n",
    "stats = {\n",
    "    \"measure\": [\"mean\", \"median\", \"sd\"],\n",
    "    **{model: [res_df[model].mean(), res_df[model].median(), res_df[model].std()] for model in res_df.columns if model != \"measure\"}\n",
    "}\n",
    "\n",
    "stats_df = pd.DataFrame(stats)\n",
    "result_df = pd.concat([res_df, stats_df], ignore_index=True)\n",
    "\n",
    "result_df.to_csv(\"outputs/model_perf_real_large.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.4824275e-06, 7.4824275e-06, 7.4824275e-06, 7.4824275e-06,\n",
       "       7.4824275e-06, 7.4824275e-06, 7.4824275e-06, 7.4824275e-06,\n",
       "       7.4824275e-06, 7.4824275e-06, 7.4824275e-06, 7.4824275e-06,\n",
       "       7.4824275e-06, 7.4824275e-06, 7.4824275e-06, 7.4824275e-06,\n",
       "       7.4824275e-06, 7.4824275e-06, 7.4824275e-06, 7.4824275e-06,\n",
       "       7.4824275e-06, 7.4824275e-06, 7.4824275e-06, 7.4824275e-06,\n",
       "       7.4824275e-06, 7.4824275e-06, 7.4824275e-06, 7.4824275e-06,\n",
       "       7.4824275e-06, 7.4824275e-06, 7.4824275e-06, 7.4824275e-06,\n",
       "       7.4824275e-06, 7.4824275e-06, 7.4824275e-06, 7.4824275e-06,\n",
       "       7.4824275e-06, 7.4824275e-06, 7.4824275e-06, 7.4824275e-06,\n",
       "       7.4824275e-06, 7.4824275e-06, 7.4824275e-06, 7.4824275e-06,\n",
       "       7.4824275e-06, 7.4824275e-06, 7.4824275e-06, 7.4824275e-06,\n",
       "       7.4824275e-06, 7.4824275e-06, 7.4824275e-06, 7.4824275e-06,\n",
       "       7.4824275e-06, 7.4824275e-06, 7.4824275e-06, 7.4824275e-06,\n",
       "       7.4824275e-06])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.effect(data_train[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.04661926, 0.41036313, 0.        , 0.36303832,\n",
       "        0.        , 0.1912369 , 0.14854852, 0.        , 1.        ,\n",
       "        1.        , 0.14350904, 0.02325581],\n",
       "       [0.47635596, 0.12348588, 0.51264176, 0.21594039, 0.29625462,\n",
       "        0.65727276, 0.78751862, 0.67220256, 0.        , 0.40713909,\n",
       "        0.        , 0.73336052, 0.04651163],\n",
       "       [0.0043664 , 0.09757693, 0.42409739, 0.04309988, 0.84001106,\n",
       "        1.        , 0.        , 0.71209386, 0.        , 0.67348034,\n",
       "        0.        , 0.26741266, 0.15332531],\n",
       "       [0.13319402, 0.13667178, 0.58870045, 0.1780911 , 0.49737168,\n",
       "        0.71158656, 0.42246287, 0.4264158 , 0.        , 0.        ,\n",
       "        0.        , 0.31777496, 0.07641196],\n",
       "       [0.30738669, 0.06268561, 0.54833004, 1.        , 0.30245259,\n",
       "        0.22003097, 0.72233636, 0.55567999, 0.        , 0.        ,\n",
       "        0.        , 0.53332655, 0.0166113 ],\n",
       "       [0.1030535 , 0.31624381, 0.55967121, 0.        , 0.71333525,\n",
       "        0.30649038, 0.96784861, 0.38632617, 0.        , 0.58146692,\n",
       "        0.        , 0.10719912, 1.        ],\n",
       "       [0.27218128, 0.12967839, 0.60566018, 0.57546243, 0.34700429,\n",
       "        0.71618455, 0.86444457, 0.5521831 , 0.        , 0.        ,\n",
       "        0.        , 0.56048951, 0.06644518],\n",
       "       [0.00922444, 0.21323096, 0.52814483, 0.02986204, 1.        ,\n",
       "        0.8651434 , 0.4578958 , 0.60808996, 0.        , 0.43432106,\n",
       "        0.        , 0.41996553, 0.06312292],\n",
       "       [0.04849349, 0.18982766, 0.33732182, 0.27375291, 0.32667532,\n",
       "        0.77437307, 0.56809829, 0.90762152, 0.        , 0.50849812,\n",
       "        0.        , 0.30737666, 0.01993355],\n",
       "       [0.17097899, 0.03199392, 0.60139424, 0.25401939, 0.50526442,\n",
       "        0.43141926, 0.57862087, 0.52139136, 0.        , 0.61678188,\n",
       "        0.        , 0.76781389, 0.02821565],\n",
       "       [0.3043597 , 0.07089295, 0.52648007, 0.18946981, 0.44523686,\n",
       "        0.30310858, 0.47217651, 0.29356634, 0.        , 0.        ,\n",
       "        1.        , 0.23489358, 0.089701  ],\n",
       "       [0.07873335, 0.18996768, 0.19581729, 0.10920208, 0.75090658,\n",
       "        0.76952406, 0.42385773, 0.66963709, 0.        , 0.67010398,\n",
       "        1.        , 0.07074292, 0.06312292],\n",
       "       [0.05903051, 0.13407107, 0.50639892, 0.17209093, 0.52349368,\n",
       "        0.98431514, 0.52610909, 0.9463029 , 0.        , 0.71490029,\n",
       "        0.        , 0.28248388, 0.28903654],\n",
       "       [0.04718696, 0.20772516, 0.59327854, 0.20308159, 0.56635361,\n",
       "        0.83980589, 0.94053931, 0.58599942, 0.        , 0.54255169,\n",
       "        0.        , 0.18346052, 0.19262676],\n",
       "       [0.0052924 , 0.24641073, 0.53979815, 0.        , 0.68830661,\n",
       "        0.68133204, 0.30888159, 0.35640037, 0.        , 0.32270418,\n",
       "        0.        , 0.80032992, 0.11757547],\n",
       "       [0.07849469, 0.        , 0.38788888, 0.12395522, 0.59417252,\n",
       "        0.75698587, 0.27522445, 0.50363017, 0.        , 0.        ,\n",
       "        0.        , 0.49954725, 0.10963455],\n",
       "       [0.06586136, 0.80191859, 0.41213193, 0.21298698, 0.77808841,\n",
       "        0.5946789 , 0.69490114, 0.42973635, 0.        , 0.        ,\n",
       "        0.        , 0.58511704, 0.04318937],\n",
       "       [0.19792121, 0.77075162, 0.51586724, 0.17072106, 0.56250297,\n",
       "        0.09337859, 0.75974114, 0.3999873 , 0.        , 0.        ,\n",
       "        1.        , 0.60170392, 0.04318937],\n",
       "       [0.34417585, 0.15568119, 0.4947456 , 0.41512243, 0.34231569,\n",
       "        0.67677946, 0.97016878, 0.93461555, 0.        , 0.42887067,\n",
       "        0.        , 0.34988652, 0.09966777],\n",
       "       [0.08290885, 0.44044143, 0.58557902, 0.24841693, 0.51363261,\n",
       "        0.38954587, 0.75685286, 0.70856105, 0.        , 0.70121679,\n",
       "        0.        , 0.80709246, 0.04503599],\n",
       "       [0.83509582, 0.36983164, 0.        , 0.73031064, 0.        ,\n",
       "        0.04854731, 0.80383123, 0.49528364, 0.        , 0.        ,\n",
       "        0.        , 0.42890647, 0.05647841],\n",
       "       [0.05780495, 0.2180018 , 0.486838  , 0.24272122, 0.5347817 ,\n",
       "        0.63754869, 0.53648829, 0.44112494, 0.        , 0.86920261,\n",
       "        0.        , 0.13531306, 0.05315615],\n",
       "       [0.1752201 , 0.25065232, 0.62209968, 0.42381459, 0.38506304,\n",
       "        0.46647168, 0.56842542, 0.43750288, 0.        , 0.78039883,\n",
       "        0.        , 0.31461496, 0.04983389],\n",
       "       [0.04092851, 0.1876526 , 0.61179898, 0.12471091, 0.91653784,\n",
       "        0.60375374, 0.77618983, 0.68063027, 0.        , 0.72319895,\n",
       "        0.        , 0.43411298, 0.09966777],\n",
       "       [0.        , 1.        , 0.31588804, 0.14993695, 0.80257344,\n",
       "        0.7098346 , 0.04879486, 0.30692832, 0.        , 0.54041291,\n",
       "        0.        , 0.50185987, 0.04651163],\n",
       "       [0.11652897, 0.21716712, 0.51076891, 0.36003178, 0.31799109,\n",
       "        0.71169633, 0.53643297, 0.77884651, 0.        , 0.        ,\n",
       "        0.        , 0.31363795, 0.68106312],\n",
       "       [0.19822977, 0.26942921, 0.45323067, 0.19042283, 0.55804309,\n",
       "        0.33620514, 0.7121221 , 0.50949443, 0.        , 0.91966687,\n",
       "        1.        , 0.78362793, 0.09302326],\n",
       "       [0.23995902, 0.14711897, 0.5682031 , 0.40433354, 0.37555218,\n",
       "        0.28963763, 0.97626951, 0.31020975, 0.        , 0.52797404,\n",
       "        0.        , 0.51888669, 0.11960133],\n",
       "       [0.01008332, 0.73440862, 0.4743523 , 0.281082  , 0.53597442,\n",
       "        0.93279349, 0.98810149, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.44960215, 0.06467972],\n",
       "       [0.05943297, 0.12935148, 0.42628238, 0.        , 0.58574721,\n",
       "        0.66181592, 0.51394579, 0.6394464 , 0.        , 0.76887888,\n",
       "        0.        , 0.62240515, 0.16611296],\n",
       "       [0.22900203, 0.17924759, 0.67256269, 0.44230442, 0.24485636,\n",
       "        0.56100027, 0.95186711, 0.55863825, 0.        , 0.        ,\n",
       "        0.        , 0.20519614, 0.13289037],\n",
       "       [0.30787787, 0.00497471, 0.45624805, 0.56652719, 0.1671298 ,\n",
       "        0.92854032, 0.84245983, 0.4516573 , 0.        , 0.        ,\n",
       "        0.        , 0.36315408, 0.09966777],\n",
       "       [0.0094967 , 0.28091848, 0.55748621, 0.11851969, 0.95203484,\n",
       "        0.92518798, 0.46062588, 0.55992119, 0.        , 0.29159136,\n",
       "        0.        , 0.49709304, 0.06976744],\n",
       "       [0.15538936, 0.09224673, 0.46561232, 0.46641595, 0.27273143,\n",
       "        0.73674823, 0.70029317, 0.69507605, 0.        , 0.        ,\n",
       "        0.        , 0.71171888, 0.19269103],\n",
       "       [0.35410427, 0.15546072, 0.47247945, 0.75758838, 0.15170665,\n",
       "        0.81856297, 0.87011322, 0.75134466, 0.        , 0.        ,\n",
       "        0.        , 0.58275551, 0.22259136],\n",
       "       [0.36654668, 0.18047062, 0.52096556, 0.50386588, 0.21061945,\n",
       "        0.34074898, 0.56561207, 0.37423259, 0.        , 0.77762305,\n",
       "        0.        , 0.2813208 , 0.00332226],\n",
       "       [0.1425813 , 0.18862349, 0.34647799, 0.4243291 , 0.30471267,\n",
       "        0.93449648, 0.75490234, 1.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.44186047],\n",
       "       [0.475345  , 0.69328478, 0.69722193, 0.15222047, 0.26590388,\n",
       "        0.00260658, 0.52252905, 0.48113995, 0.        , 0.55856952,\n",
       "        0.        , 0.58358629, 0.01732553],\n",
       "       [0.00216612, 0.06079608, 0.4480283 , 0.28242743, 0.76714694,\n",
       "        0.93819228, 0.70719204, 0.90066627, 0.        , 0.59293303,\n",
       "        0.        , 0.44234385, 0.24916944],\n",
       "       [0.20890965, 0.2475951 , 0.47091874, 0.44371084, 0.28014995,\n",
       "        0.67683303, 0.29320372, 0.80721867, 0.        , 0.80570858,\n",
       "        0.        , 0.2853764 , 0.0166113 ],\n",
       "       [0.02880364, 0.67546113, 0.59629591, 0.        , 0.81769354,\n",
       "        0.47784802, 0.3010175 , 0.34612422, 0.        , 0.88176602,\n",
       "        1.        , 0.39459112, 0.30533018],\n",
       "       [0.27929284, 0.23496077, 0.55322027, 0.45131543, 0.4120551 ,\n",
       "        0.1887761 , 1.        , 0.45910801, 0.        , 0.44148403,\n",
       "        0.        , 0.56579254, 0.07641196],\n",
       "       [0.04756695, 0.29071697, 0.51638747, 0.11619169, 0.76924698,\n",
       "        0.3377833 , 0.8131231 , 0.41058438, 0.        , 0.51875598,\n",
       "        1.        , 0.        , 0.11627907],\n",
       "       [0.04129918, 0.09503435, 0.57590261, 0.13384924, 0.6950939 ,\n",
       "        0.77982723, 0.56369018, 0.63991666, 0.        , 0.        ,\n",
       "        0.        , 0.50216182, 0.04318937],\n",
       "       [0.06445765, 0.2302699 , 0.55634169, 0.16113961, 0.46221119,\n",
       "        0.77039911, 0.53956874, 0.53308904, 0.        , 0.65431675,\n",
       "        0.        , 0.3562085 , 0.06644518],\n",
       "       [0.43332999, 0.03756336, 1.        , 0.55018596, 0.37146839,\n",
       "        0.28956323, 0.69640127, 0.66467234, 0.        , 0.77206072,\n",
       "        0.        , 0.41450708, 0.07973422],\n",
       "       [0.50661022, 0.89118602, 0.3320154 , 0.54037737, 0.15957227,\n",
       "        0.03433058, 0.46547622, 0.41337698, 0.        , 0.        ,\n",
       "        0.        , 0.7176281 , 0.0503472 ],\n",
       "       [0.19502544, 0.07207025, 0.46592446, 0.45509504, 0.39340925,\n",
       "        0.62565431, 0.58539397, 0.54477409, 0.        , 0.78468618,\n",
       "        0.        , 0.33772382, 0.24576636],\n",
       "       [0.2887752 , 0.11974545, 0.52980959, 0.24861044, 0.47189617,\n",
       "        0.76653636, 0.86661948, 0.6744373 , 0.        , 0.33148088,\n",
       "        0.        , 0.63580479, 0.16943522],\n",
       "       [0.45110961, 0.24666469, 0.60056186, 0.493164  , 0.26500679,\n",
       "        0.0521535 , 0.25741888, 0.14456037, 0.        , 0.        ,\n",
       "        0.        , 0.4336792 , 0.        ],\n",
       "       [0.37503147, 0.0631563 , 0.55738217, 0.29229926, 0.20186792,\n",
       "        0.12104599, 0.5869604 , 0.38666013, 0.        , 0.        ,\n",
       "        0.        , 0.59712674, 0.00996678],\n",
       "       [0.26874698, 0.11508688, 0.92290084, 0.34475715, 0.26493238,\n",
       "        0.22146865, 0.88102712, 0.16027614, 0.        , 0.52700306,\n",
       "        0.        , 0.31523286, 0.03322259],\n",
       "       [0.24705884, 0.41296214, 0.58838831, 0.26474366, 0.48683723,\n",
       "        0.63038277, 0.51789905, 0.67749159, 0.        , 0.62788652,\n",
       "        0.        , 0.43411673, 0.04318937],\n",
       "       [0.25147012, 0.2038884 , 0.49703465, 0.06567414, 0.50971717,\n",
       "        0.1906209 , 0.57739634, 0.47475985, 0.        , 0.58911453,\n",
       "        0.        , 0.67658276, 0.03140794],\n",
       "       [0.35829913, 0.15572325, 0.50962439, 0.13314486, 0.44895919,\n",
       "        0.15204063, 0.63484354, 0.45982636, 0.        , 0.        ,\n",
       "        0.        , 0.40364761, 0.02930952],\n",
       "       [0.07068702, 0.61277681, 0.52523151, 0.24859868, 0.58771933,\n",
       "        0.45500954, 0.76153467, 0.50924777, 0.        , 0.        ,\n",
       "        0.        , 0.22212388, 0.09302326],\n",
       "       [0.00139688, 0.59451899, 0.5313703 , 0.21689195, 0.37439979,\n",
       "        0.3068746 , 0.65087444, 0.17629111, 0.        , 0.95910317,\n",
       "        0.        , 0.36083687, 0.05489423]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.82898736e-05 8.06912280e-05 1.58342612e-04 1.48260758e-04\n",
      " 1.04515424e-04 2.05019714e-04 7.51803928e-05 1.29557206e-04\n",
      " 1.20431555e-04 1.07167343e-04 6.21059102e-05 1.26520804e-04\n",
      " 1.33856397e-04 1.96867203e-04 1.03969898e-04 2.90592344e-05\n",
      " 7.21008670e-05 9.98668410e-05 1.63306101e-04 1.18554095e-04\n",
      " 1.28163197e-04 1.48294383e-04 1.63336644e-04 1.89053821e-04\n",
      " 3.46941287e-05 1.03626395e-04 8.09525878e-05 1.79945671e-04\n",
      " 3.99367222e-05 8.30793869e-05 2.09858864e-04 1.10884541e-04\n",
      " 1.41320709e-04 1.11320742e-04 8.22730143e-05 8.90907170e-05\n",
      " 8.78664548e-05 1.14513552e-04 1.58045252e-04 1.30629001e-04\n",
      " 7.39083154e-05 1.06558097e-04 7.25376011e-05 6.50190675e-05\n",
      " 1.11199138e-04 1.61263494e-04 8.35910303e-05 1.28613008e-04\n",
      " 1.09680607e-04 8.47472462e-05 9.82164299e-05 1.95272842e-04\n",
      " 5.45455147e-05 8.40419820e-05 1.20050977e-04 1.55343263e-04\n",
      " 1.11024658e-04]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from econml.dml import CausalForestDML\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Example data\n",
    "# Assuming data_train is the covariate matrix X, \n",
    "# treatment is the binary treatment variable (1 for treated, 0 for control),\n",
    "# and outcome is the observed outcome variable\n",
    "X = data_train  # your covariates\n",
    "treatment = np.random.randint(0, 2, size=X.shape[0])  # example treatment variable (binary)\n",
    "outcome = np.random.randn(X.shape[0])  # example outcome (continuous)\n",
    "\n",
    "# Split data into train/test\n",
    "X_train, X_test, y_train, y_test, treatment_train, treatment_test = train_test_split(X, outcome, treatment, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit Causal Forest\n",
    "causal_forest = CausalForestDML(model_y=RandomForestRegressor(), model_t=RandomForestRegressor(), n_estimators=100)\n",
    "causal_forest.fit(data_train[:,0], data_train[:,1], X=data_train[:,2:])\n",
    "\n",
    "# Predict treatment effects for the test set\n",
    "treatment_effects = causal_forest.effect(data_test[:,2:])\n",
    "\n",
    "# View the estimated treatment effects\n",
    "print(treatment_effects)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
