{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from main import *\n",
    "from eval_cf_MISE import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Data \n",
    "# Data train\n",
    "df = pd.read_csv('data/Sim_data_train.csv')\n",
    "data_train = df.to_numpy()\n",
    "\n",
    "# Data test counterfactual\n",
    "data_cf = np.load('data/data_cf.npz')\n",
    "A_cf = data_cf['A_cf']\n",
    "Y_cf = data_cf['Y_cf']\n",
    "X_cf = data_cf['X_cf']\n",
    "\n",
    "# Hyperpar list\n",
    "hyper_opt_list = open(\"hyperpars/hyperpars_opt_real_large.txt\", \"r\")\n",
    "hyper_opt_list = hyper_opt_list.read()\n",
    "hyper_opt = ast.literal_eval(hyper_opt_list)\n",
    "\n",
    "# Convert hyperpar_opt_list so that its values are iterable\n",
    "for i in range(len(hyper_opt)):\n",
    "    for key in hyper_opt[i].keys():\n",
    "        hyper_opt[i][key] = [hyper_opt[i][key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Counterfactual point estimate and variance (averaged over 10 runs)\n",
    "\n",
    "models = ['lm', 'nn', 'gps', 'dr', 'sci', 'cgct_gps', 'rf', 'cgct_rf']\n",
    "# Set all seeds\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Get results\n",
    "res_table = np.empty(shape=(8,10))\n",
    "for l in range(10):\n",
    "    test_loss = []\n",
    "    for i, model in enumerate(models):\n",
    "        cv_results = eval_MISE(data_train, X_cf, A_cf, Y_cf, model, hyper_opt[i])\n",
    "        test_loss.append(cv_results[0]['loss'])\n",
    "    res_table[:,l] = np.array(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   measure       lm        nn       gps        dr        sci  cgct_gps  \\\n",
      "0    run 1  0.17318  0.600140  0.210394  0.806490   4.428555  0.332491   \n",
      "1    run 2  0.17318  0.378943  0.210394  0.696156   3.802102  0.337377   \n",
      "2    run 3  0.17318  0.253374  0.210394  0.552711   1.726807  0.340213   \n",
      "3    run 4  0.17318  0.200030  0.210394  0.449337   5.768789  0.338559   \n",
      "4    run 5  0.17318  0.524151  0.210394  0.742749   5.610894  0.340803   \n",
      "5    run 6  0.17318  0.268141  0.210394  0.452694   2.277125  0.333515   \n",
      "6    run 7  0.17318  0.608851  0.210394  0.478910   8.484173  0.338309   \n",
      "7    run 8  0.17318  0.230941  0.210394  0.635279   7.702509  0.333403   \n",
      "8    run 9  0.17318  0.222312  0.210394  0.268998  11.097772  0.333201   \n",
      "9   run 10  0.17318  0.474266  0.210394  0.338369  15.791056  0.326564   \n",
      "10    mean  0.17318  0.376115  0.210394  0.542169   6.668978  0.335444   \n",
      "11  median  0.17318  0.323542  0.210394  0.515810   5.689841  0.335446   \n",
      "12      sd  0.00000  0.162744  0.000000  0.176186   4.295623  0.004392   \n",
      "\n",
      "          rf   cgct_rf  \n",
      "0   0.171173  0.392607  \n",
      "1   0.171173  0.399686  \n",
      "2   0.171173  0.414109  \n",
      "3   0.171173  0.375260  \n",
      "4   0.171173  0.389804  \n",
      "5   0.171173  0.325669  \n",
      "6   0.171173  0.331831  \n",
      "7   0.171173  0.352366  \n",
      "8   0.171173  0.333515  \n",
      "9   0.171173  0.399100  \n",
      "10  0.171173  0.371395  \n",
      "11  0.171173  0.382532  \n",
      "12  0.000000  0.032744  \n"
     ]
    }
   ],
   "source": [
    "#Get results into format for export\n",
    "\n",
    "df = pd.DataFrame(np.transpose(res_table), columns=models)\n",
    "df.insert(0, \"measure\", [f\"run {i+1}\" for i in range(len(res_table.T))])\n",
    "\n",
    "stats = {\n",
    "    \"measure\": [\"mean\", \"median\", \"sd\"],\n",
    "    **{model: [df[model].mean(), df[model].median(), df[model].std()] for model in df.columns if model != \"measure\"}\n",
    "}\n",
    "\n",
    "stats_df = pd.DataFrame(stats)\n",
    "result_df = pd.concat([df, stats_df], ignore_index=True)\n",
    "\n",
    "result_df.to_csv(\"outputs/model_perf_sim.csv\")\n",
    "\n",
    "print(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
